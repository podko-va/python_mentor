from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
import pandas as pd
import time

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±—Ä–∞—É–∑–µ—Ä–∞
options = webdriver.ChromeOptions()
options.add_argument("--headless")
options.add_argument("user-agent=Mozilla/5.0")

# –ó–∞–ø—É—Å–∫ –¥—Ä–∞–π–≤–µ—Ä–∞
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
wait = WebDriverWait(driver, 10)

# –î–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
college_links = []
results = []

try:
    # –®–∞–≥ 1: –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∫–æ–ª–ª–µ–¥–∂–µ–π
    base_url = "https://www.baseball-almanac.com/college/colleges_sort_quantity.shtml"
    driver.get(base_url)
    wait.until(EC.presence_of_element_located((By.TAG_NAME, "table")))

    rows = driver.find_elements(By.TAG_NAME, "tr")[1:]  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫

    for row in rows:
        try:
            cells = row.find_elements(By.TAG_NAME, "td")
            if len(cells) >= 2:
                link_el = cells[0].find_element(By.TAG_NAME, "a")
                college_link = link_el.get_attribute("href")
                title = cells[0].text.strip()
                college_name = title.split("|")[0].strip()
                college_qty = cells[1].text.strip()
                college_links.append((college_name, college_qty, college_link))
        except Exception as e:
            print(f"‚ö†Ô∏è Skipping college row due to error: {e}")

    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ª–ª–µ–¥–∂–µ–π –¥–ª—è —Ç–µ—Å—Ç–∞ (—Å–Ω–∏–º–∞–π –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø—Ä–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º –∑–∞–ø—É—Å–∫–µ)
    college_links = college_links[:30]

    # –®–∞–≥ 2: –ü–∞—Ä—Å–∏–Ω–≥ –∏–≥—Ä–æ–∫–æ–≤ —Å –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–æ–ª–ª–µ–¥–∂–∞
    for college_name, college_qty, college_url in college_links:
        try:
            print(f"üîç Scraping: {college_name} ({college_qty} players)")
            driver.get(college_url)
            time.sleep(2)  # –ü–∞—É–∑–∞ –¥–ª—è –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –∏–∑–±–µ–∂–∞–Ω–∏—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏

            table = wait.until(EC.presence_of_element_located((By.TAG_NAME, "table")))
            player_rows = table.find_elements(By.TAG_NAME, "tr")[1:]  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫

            for row in player_rows:
                try:
                    cells = row.find_elements(By.TAG_NAME, "td")
                    if len(cells) >= 3:
                        player_name = cells[1].text.strip()
                        if not player_name:
                            continue
                        years_raw = cells[2].text.strip()
                        if "-" in years_raw:
                            end_year = years_raw.split("-")[-1].strip()
                        else:
                            end_year = years_raw[-4:]  # –ï—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –¥—Ä—É–≥–æ–π, –±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 4 —Å–∏–º–≤–æ–ª–∞
                        results.append([college_name, college_qty, player_name, end_year])
                except Exception as e:
                    print(f"‚ö†Ô∏è Skipping player row: {e}")
        except Exception as e:
            print(f"‚ùå Could not scrape {college_name}: {e}")

finally:
    driver.quit()

# –®–∞–≥ 3: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ CSV
try:
    df = pd.DataFrame(results, columns=["College", "Players Qty", "Player", "End Year"])
    df.to_csv("my_mlb_data.csv", index=False, encoding="utf-8")
    print("‚úÖ Data saved to my_mlb_data.csv")
except Exception as e:
    print(f"‚ùå Error saving file: {e}")
